
blueprint:
  name: AI Event Summary (LLM Vision v1.3.1)
  author: valentinfrlch
  description: >
    AI-powered security event summaries for Frigate or camera entities.
    Sends a notification with a preview to your phone that is updated dynamically when the AI summary is available.
  domain: automation
  source_url: https://github.com/valentinfrlch/ha-llmvision/blob/main/blueprints/event_summary.yaml
  input:
    mode:
      name: Mode
      description: Select the mode to use
      selector:
        select:
          options:
            - 'Frigate'
            - 'Camera'
    important:
      name: Important (Beta)
      description: >
        Use AI to classify events into 'critical', 'normal' and 'low'.
        Notifications will only be sent when an event is classified as at least 'normal'.
        For critical events, the notification will be delivered even if 'Do not disturb' is on.
        Use with caution: AI can make mistakes.
      default: false
      selector:
        boolean:
    remember:
      name: Remember
      description: Remember this event so you can ask about it later. Event Calendar needs to be configured. If 'important' is set to true, only events classified as 'normal' or higher will be remembered.
      default: false
      selector:
        boolean:
    notify_device:
      name: Notify Device
      description: The devices to send the notification to. Multiple devices may be used. Only works with Home Assistant mobile app.
      default: []
      selector:
        device:
          multiple: true
          filter:
            integration: mobile_app
    camera_entities:
      name: Camera Entities
      description: >
        (Camera and Frigate mode)

        List of camera entities to monitor
      default: []
      selector:
        entity:
          multiple: true
          filter:
            domain: camera
    object_type:
      name: Included Object Type(s)
      description: >
        (Frigate mode only)

        Only run if Frigate labels the object as one of these. (person, dog, bird, etc)
      default: []
      selector:
        text:
          multiline: false
          multiple: true
    trigger_state:
      name: Trigger State
      description: >
        (Camera mode only)

        Trigger the automation when your cameras change to this state.
      default: 'recording'
      selector:
        text:
          multiline: false
    motion_sensors:
      name: Motion Sensor
      description: >
        (Camera mode only)

        Set if your cameras don't change state. Use the same order used for camera entities.
      default: []
      selector:
        entity:
          multiple: true
          filter:
            domain: binary_sensor
    preview_mode:
      name: Preview Mode
      description: >
        (Camera mode only)

        Choose between a live preview or a snapshot of the event
      default: 'Live Preview'
      selector:
        select:
          options:
            - 'Live Preview'
            - 'Snapshot'
    cooldown:
      name: Cooldown
      description: Time in minutes to wait before running again. Recommended for busy areas.
      default: 10
      selector:
        number:
          min: 0
          max: 60
    tap_navigate:
      name: Tap Navigate
      description: >
        Path to navigate to when notification is opened (e.g. /lovelace/cameras).

        To use the same input which was sent to the AI engine, use
          `{{video if video != '' else image}}`
      default: "/lovelace/0"
      selector:
        text:
          multiline: false
    duration:
      name: Duration
      description: >
        (Camera mode only)

        How long to record before analyzing (in seconds)
      default: 5
      selector:
        number:
          min: 1
          max: 60
    max_frames:
      name: Max Frames
      description: >
        (Camera and Frigate mode)

        How many frames to analyze. Picks frames with the most movement.
      default: 3
      selector:
        number:
          min: 1
          max: 60
    provider:
      name: Provider
      description: Provider to use for analysis. See docs for additional information.
      selector:
        config_entry:
          integration: llmvision
    model:
      name: Model
      description: Model to use for the video_analyzer action. Leave blank to automatically detect the best model.
      default: "gpt-4o-mini"
      selector:
        text:
          multiline: false
    message:
      name: Prompt
      description: Model prompt for the video_analyzer action
      default: "Summarize what's happening in the camera feed (one sentence max). Don't describe the scene! If there is a person, describe what they're doing and what they look like. If they look like a courier mention that! If nothing is happening, say so."
      selector:
        text:
          multiline: true
    target_width:
      name: Target Width
      description: Downscale images (uses less tokens and speeds up processing)
      default: 1280
      selector:
        number:
          min: 512
          max: 3840
    max_tokens:
      name: Maximum Tokens
      description: Maximum number of tokens to generate. Use this to control the length of the summaries.
      default: 20
      selector:
        number:
          min: 1
          max: 100
    detail:
      name: Detail
      description: Detail parameter (OpenAI only)
      default: 'low'
      selector:
        select:
          options:
            - 'high'
            - 'low'
    temperature:
      name: Temperature
      description: Randomness. Lower is more accurate, higher is more creative.
      default: 0.1
      selector:
        number:
          min: 0.1
          max: 1.0
          step: 0.1

# Add the "analyze fixes" for variables and trigger handling below (truncated for demonstration)
